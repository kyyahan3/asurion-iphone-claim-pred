{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel(\"/data/p_dsi/teams2023/team1/iphone_data.xlsx\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "- Add a \"day\" column, from the existing ones\n",
    "- Set \"phone size\" and \"weeks_since_release\" columns to have integer values\n",
    "- Drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['day'] = pd.to_datetime(df['weeks_monday']).dt.day\n",
    "df['phone size'] = df['phone size'].apply(lambda x: int(x.replace('gb', '')))\n",
    "df['weeks_since_release'] = df['weeks_since_release'].apply(lambda x: int(x))\n",
    "\n",
    "# Drop unneeded columns - identical over all rows, or correlated with other engineered columns\n",
    "df.drop(['model', 'brand','release'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Outliers\n",
    "\n",
    "Since the last week for which we have data has much smaller values than what is expected, we proceed with the assumption that we do not have data for the whole week, which is why that number is much lower. Therefore, we drop it to avoid this outlier affecting the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['weeks_monday'] != '2023-02-13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "\n",
    "We use last 8 weeks for test data, which at the moment is only 3.5% of the data. We do this to make sure that we include iPhone 14 values in the training data, so the model is aware that that trend exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_time = ['2023-02-06', '2023-01-30', '2023-01-23', '2023-01-16', '2023-01-09', '2023-01-02', '2022-12-26', '2022-12-19']\n",
    "\n",
    "test_data = df.loc[df['weeks_monday'].isin(test_time)]\n",
    "train_data = df.loc[~df['weeks_monday'].isin(test_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates in Test Data: ['2022-12-19T00:00:00.000000000' '2022-12-26T00:00:00.000000000'\n",
      " '2023-01-02T00:00:00.000000000' '2023-01-09T00:00:00.000000000'\n",
      " '2023-01-16T00:00:00.000000000' '2023-01-23T00:00:00.000000000'\n",
      " '2023-01-30T00:00:00.000000000' '2023-02-06T00:00:00.000000000']\n",
      "Size of Train Data: 1205 ; Size of Test Data: 46\n",
      "Test Data is  3.8174273858921164 % of Train Data\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that we only have the dates we wanted.\n",
    "print(\"Dates in Test Data:\", test_data['weeks_monday'].unique())\n",
    "print(\"Size of Train Data:\", len(train_data), \"; Size of Test Data:\", len(test_data))\n",
    "print(\"Test Data is \", len(test_data)/len(train_data) * 100, \"% of Train Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True)\n",
    "train_data.to_excel(\"/data/p_dsi/teams2023/team1/train_data.xlsx\")\n",
    "\n",
    "test_data.reset_index(drop=True)\n",
    "test_data.to_excel(\"/data/p_dsi/teams2023/team1/test_data.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4533c38f734945b145a0b739c2b06b7f9f86210b5735e7bb705d4e9923f99e0d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
